---
description: LLM Quest Benchmark Project
globs: 
---
################################################################################
#  Rules for llm-quest-benchmark project     #
################################################################################

PROJECT_NAME: llm-quest-benchmark
GOAL: Benchmark LLM performance on Space Rangers text quests; build a robust evaluation framework. Target: Next Week.
VERSION: 0.2.0

# Core Principles (Specific to this project)
PROJECT_PRINCIPLES:
  - QM_FIRST: Focus on Space Rangers quests, use space-rangers-quest submodule for parsing as is
  - DEVELOPER_HAPPINESS: Prioritize interesting tech and rapid iteration.
  - MINIMAL_TEXTARENA: Use TextArena for infrastructure, but keep custom components focused.

# Key Files/Directories (Update this as your project evolves)
# This section provides a high-level overview, not an exhaustive list.
CONTEXT_FILES:
  - README.md: Project overview and setup.
  - roadmap.md: Project roadmap.
  - llm_quest_benchmark/scripts/run_quest.py: Main benchmarking script.
  - space-rangers-quest/src/lib/qmreader.ts: QM parser (TypeScript).
  - llm_quest_benchmark/agents/llm_agent.py: Example LLM agent.

# Tools and Commands (Specific to this project)
# Provide concise descriptions and usage examples.
TOOLS:
  - uv: Modern Python package manager (Required)
    - Usage: uv pip install [package]
    - Priority: 0 (Always use instead of pip)
    - Notes: 
      - Use for all Python package operations
      - Keep uv.lock in version control
      - Use virtual environments managed by uv
  - ensure-env: Setup environment
    - Usage: source ensure_env.sh
    - Priority: 1 (Run before any Python commands)
  - goose: AI agent for complex tasks and analysis
    - Usage:
      - Run task: `goose run -t "task description"`
      - Run with file: `goose run -i instructions.txt`
      - Debug output: Add debug context to task description
    - Priority: 2 (Use for complex analysis and debugging)
  - llm-quest: CLI tool for running and playing quests
    - Usage: 
      - Run with LLM: `llm-quest run --quest <quest_path> --log-level <level>`
      - Play interactive: `llm-quest play --quest <quest_path> --log-level <level>`
      - Analyze results: `llm-quest analyze --metrics-file <metrics_file>`
  - pre-commit: Maintain code quality
    - Usage: `pre-commit run --all-files`

STANDARDS:
  - ENV_CONSISTENCY: Always use ensure_env.sh
  - LOCK_FILES: uv.lock must be committed
  - CODE_STYLE: All code must pass pre-commit checks and not duplicate existing code
  - TYPING: Use type hints for all public interfaces
  - DOCS: Keep docs updated with code changes