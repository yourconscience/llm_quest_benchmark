# Default benchmark configuration
# Includes all supported models with standardized settings

quests:
  - quests/spacerangers.gitlab.io/borrowed/qm/лџла 1

agents:
  # OpenAI models
  - model: gpt-5-mini
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  - model: gpt-4.1-mini
    template: reasoning.jinja
    temperature: 0.8
    skip_single: true

  - model: gpt-4.1-mini
    template: reasoning.jinja
    temperature: 0.6
    skip_single: true

  - model: gpt-4.1-mini
    template: reasoning.jinja
    temperature: 0.4
    skip_single: true

  - model: gpt-4.1-mini
    template: reasoning.jinja
    temperature: 0.2
    skip_single: true

  # Anthropic models
  - model: claude-sonnet-4-0
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  - model: claude-opus-4-1
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  - model: gemini-2.5-flash
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

# Debug mode enables more detailed logging
debug: true

# Output directory for benchmark results
output_dir: results/benchmarks

# Optional name for this benchmark run
name: kr1
