# Temperature comparison benchmark configuration
# Tests the effect of different temperature settings on model performance

quests:
  - quests/Boat.qm
  - quests/spacerangers.gitlab.io/borrowed/qm/лџла 1/Diehard.qm

agents:
  # OpenAI models with different temperatures
  - model: gpt-5-mini
    template: reasoning.jinja
    temperature: 0.3
    skip_single: true

  - model: gpt-5-mini
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  - model: gpt-5-mini
    template: reasoning.jinja
    temperature: 0.7
    skip_single: true

  # Anthropic models with different temperatures
  - model: claude-sonnet-4-0
    template: reasoning.jinja
    temperature: 0.3
    skip_single: true

  - model: claude-sonnet-4-0
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  - model: claude-sonnet-4-0
    template: reasoning.jinja
    temperature: 0.7
    skip_single: true

# Debug mode enables more detailed logging
debug: true

# Number of parallel workers
max_workers: 2

# Output directory for benchmark results
output_dir: results/benchmarks

# Name for this benchmark run
name: Temperature Comparison
