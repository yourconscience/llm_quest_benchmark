# Default benchmark configuration
# Includes all supported models with standardized settings

quests:
  - quests/Boat.qm  # Single quest for quick testing
  # Uncomment to test multiple quests:
  # - quests/kr1/Diehard.qm

agents:
  # Random baseline agent
  - model: random_choice
    template: reasoning.jinja
    temperature: 0.0
    skip_single: true

  # OpenAI models
  - model: gpt-5-mini
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  - model: gpt-4.1-mini
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  # Anthropic models
  - model: claude-sonnet-4-0
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  - model: claude-opus-4-1
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

  # Google model
  - model: gemini-2.5-flash
    template: reasoning.jinja
    temperature: 0.5
    skip_single: true

# Debug mode enables more detailed logging
debug: true

# Number of parallel workers (set higher for faster benchmarking)
max_workers: 2

# Output directory for benchmark results
output_dir: results/benchmarks

# Optional name for this benchmark run
name: Default Benchmark
