# Provider-tuned matrix built from benchmark evidence:
# - GPT-5-mini: objective guard + completion system (lower token overhead, same success as baseline)
# - Claude Sonnet 4.5: consequence scan (best observed success/cost tradeoff)
# - Gemini 2.5 Flash: consequence scan (only variant with observed success on this set)
# - DeepSeek 3.2 Chat: baseline reasoning (creative variants regressed)
name: provider_suite_matrix_provider_tuned_v1
quests:
  - quests/Boat.qm
  - quests/kr_1_ru/Fishing.qm
  - quests/kr_1_ru/Gobsaur.qm
  - quests/kr_1_ru/Rush.qm
  - quests/kr_1_ru/Examen.qm
  - quests/sr_2_1_2121_eng/Banket_eng.qm
agents:
  - model: gpt-5-mini
    system_template: system_role_completion.jinja
    template: objective_guard.jinja
    temperature: 0.4
    skip_single: true
  - model: claude-sonnet-4-5
    template: consequence_scan.jinja
    temperature: 0.4
    skip_single: true
  - model: gemini-2.5-flash
    template: consequence_scan.jinja
    temperature: 0.4
    skip_single: true
  - model: deepseek-3.2-chat
    template: reasoning.jinja
    temperature: 0.4
    skip_single: true
debug: true
quest_timeout: 60
max_workers: 2
output_dir: results/benchmarks
