# Main LLM benchmark configuration
quests:
  - quests/test  # Example quests dir, will be replaced with actual quest paths
agents:
  # - model: random_choice
  - model: claude-3-5-sonnet-20241022
    skip_single: true
  - model: gpt-4o
    skip_single: true
debug: false
quest_timeout: 90
max_workers: 2
output_dir: metrics/benchmarks