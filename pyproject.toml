[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"


[project]
name = "llm_quest_benchmark"
version = "0.1.0"
description = "LLM Quest Benchmark using Space Rangers quests"
authors = [
    {name = "Kirill Korikov", email = "kirill.korikov@gmail.com"},
]
dependencies = [
    "rich>=13.0.0",
    "typer>=0.9.0",
    "jinja2>=3.1.2",
    "openai>=1.12.0",
    "litellm>=1.2.1",
    "anthropic>=0.13.0",
    "json-repair>=0.39.0",
    "streamlit>=1.32.0",
    "sqlite3>=0.0.1",  # Explicitly declare even if stdlib
    "pyyaml>=6.0.1",
]

[project.optional-dependencies]
dev = [
    "pre-commit>=3.0.0",
    "yapf>=0.34.0",
    "isort>=5.13.0",
    "types-pyyaml>=6.0.12",
]
test = [
    "pytest>=8.0.0",
    "pytest-cov>=4.1.0",
    "pytest-timeout>=2.0.0",
    "pytest-xdist>=3.0.0",
    "pytest-sugar>=0.9.0",
    "pytest-clarity>=1.0.0",
    "pytest-asyncio>=0.23.2",
    "streamlit-testing>=0.1.0",
]

[project.scripts]
llm-quest = "llm_quest_benchmark.executors.cli.commands:app"


[tool.setuptools]
packages = ["llm_quest_benchmark"]

[tool.setuptools.package-data]
"llm_quest_benchmark" = [
    "prompt_templates/*.jinja",
    "scripts/*.ts"
]

[tool.uv]
pip = ">=23.3.2"
resolver = "backtracking"

[tool.ruff]
line-length = 120
target-version = "py39"

[tool.pytest.ini_options]
asyncio_mode = "auto"
addopts = "-v --cov=llm_quest_benchmark --cov-report=html"
timeout = 30
